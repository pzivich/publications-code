{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3473fe-50e9-4882-b0d4-11861bef49d0",
   "metadata": {},
   "source": [
    "# G-computation Examples\n",
    "\n",
    "Python code illustrating the application of the proposed g-computation estimators to a single data set in the context of the case studies described in the paper.\n",
    "\n",
    "Paul Zivich (2024/12/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422364e9-63d4-4f3c-b965-fd01020cf2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versions\n",
      "NumPy:        1.25.2\n",
      "SciPy:        1.11.2\n",
      "Pandas:       1.4.1\n",
      "Delicatessen: 3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import delicatessen as deli\n",
    "from delicatessen import MEstimator\n",
    "from delicatessen.estimating_equations import ee_regression\n",
    "from delicatessen.utilities import inverse_logit\n",
    "\n",
    "print(\"Versions\")\n",
    "print(\"NumPy:       \", np.__version__)\n",
    "print(\"SciPy:       \", sp.__version__)\n",
    "print(\"Pandas:      \", pd.__version__)\n",
    "print(\"Delicatessen:\", deli.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28eb5e7-cc30-48f1-9920-5263ebc8f021",
   "metadata": {},
   "source": [
    "## Case 1: Treatment Induced Selection\n",
    "\n",
    "The following code analyzes an example data set generated using the mechanism described in the paper. Note the true average causal effect is -0.2187."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c6e21c-37a9-4da8-a03d-223877f9341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in example data\n",
    "d = pd.read_csv(\"example1.csv\")\n",
    "d['AW'] = d['A'] * d['W']\n",
    "\n",
    "# Generating copies of data under interventions\n",
    "da1 = d.copy()\n",
    "da1['A'] = 1\n",
    "da1['AW'] = da1['A'] * da1['W']\n",
    "da0 = d.copy()\n",
    "da0['A'] = 0\n",
    "da0['AW'] = da0['A'] * da0['W']\n",
    "\n",
    "# NumPy arrays to simplify later data management\n",
    "y = np.asarray(d['Y'])\n",
    "a = np.asarray(d['A'])\n",
    "s = np.asarray(d['S'])\n",
    "X = np.asarray(d[['I', 'A', 'W', 'AW']])\n",
    "X1 = np.asarray(da1[['I', 'A', 'W', 'AW']])\n",
    "X0 = np.asarray(da0[['I', 'A', 'W', 'AW']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59daaa01-287c-475e-a9b2-42a778dcba49",
   "metadata": {},
   "source": [
    "### Standard g-computation\n",
    "\n",
    "With treatment-induced selection bias, standard g-computation is expected to be biased, as detailed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3aca8c35-c281-4439-b95b-7664b4fd1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_sg(theta):\n",
    "    # Subset parameters for easier tracking in code later\n",
    "    rd, r1, r0 = theta[0:3]\n",
    "    beta = theta[3:]\n",
    "\n",
    "    # Outcome nuisance model\n",
    "    ee_out = ee_regression(beta, X=X, y=y, model='logistic')  # Built-in estimating equation for regression\n",
    "    ee_out = ee_out * s                                       # Fit model to only those with S=1\n",
    "    y1hat = inverse_logit(np.dot(X1, beta))                   # Predictions when setting A=1\n",
    "    y0hat = inverse_logit(np.dot(X0, beta))                   # Predictions when setting A=0\n",
    "\n",
    "    # Estimating equations for risk parameters\n",
    "    ee_r1 = y1hat - r1\n",
    "    ee_r0 = y0hat - r0\n",
    "    ee_rd = np.ones(y.shape) * (r1 - r0 - rd)\n",
    "\n",
    "    # Returning the stacked estimating functions\n",
    "    return np.vstack([ee_rd, ee_r1, ee_r0, ee_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a85cb17c-f1e2-4390-9cb5-6f0be6027575",
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = [0., 0.5, 0.5, 0., 0., 0., 0., ]\n",
    "estr = MEstimator(psi_sg, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372aa02b-3cc8-40d9-a217-88c24da71485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD: -0.36888570729462733\n",
      "95% CI: [-0.43955539 -0.29821602]\n"
     ]
    }
   ],
   "source": [
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27dc48-8ab9-4524-9808-443911c2d68f",
   "metadata": {},
   "source": [
    "### Modified g-computation\n",
    "\n",
    "The modified g-computation algorithm described in the paper is applied here. This version is expected to be unbiased."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1156dce9-f148-4cec-a595-070818bbb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_pg(theta):\n",
    "    # Subset parameters for easier tracking in code later\n",
    "    rd, r1, r0 = theta[0:3]\n",
    "    beta = theta[3:]\n",
    "\n",
    "    # Outcome nuisance model\n",
    "    ee_out = ee_regression(beta, X=X, y=y, model='logistic')  # Built-in estimating equation for regression\n",
    "    ee_out = ee_out * s                                       # Fit model to only those with S=1\n",
    "    y1hat = inverse_logit(np.dot(X1, beta))                   # Predictions when setting A=1\n",
    "    y0hat = inverse_logit(np.dot(X0, beta))                   # Predictions when setting A=0\n",
    "\n",
    "    # Estimating equations for risk parameters\n",
    "    ee_r1 = a*(y1hat - r1)\n",
    "    ee_r0 = (1-a)*(y0hat - r0)\n",
    "    ee_rd = np.ones(y.shape) * (r1 - r0 - rd)\n",
    "\n",
    "    # Returning the stacked estimating functions\n",
    "    return np.vstack([ee_rd, ee_r1, ee_r0, ee_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cbed4fa-0e19-4009-afae-ddf8c2e167c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = [0., 0.5, 0.5, 0., 0., 0., 0., ]\n",
    "estr = MEstimator(psi_pg, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef0dce8-6118-4045-9266-5e72b8bac9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD: -0.25351223589731836\n",
      "95% CI: [-0.32528575 -0.18173872]\n"
     ]
    }
   ],
   "source": [
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a90a35-764e-4486-90c6-d1e43c5723cc",
   "metadata": {},
   "source": [
    "This concludes the first case study.\n",
    "\n",
    "## Case 2: Confounding and Selection Bias\n",
    "\n",
    "The following code analyzes an example data set generated using the mechanism described in the paper. Note the true average causal effect is -0.2049."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9d73f88-6b3e-4e6e-a852-e765c4e7e7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in example data\n",
    "d = pd.read_csv(\"example2.csv\")\n",
    "\n",
    "# Generating copies of data under interventions\n",
    "da1 = d.copy()\n",
    "da1['A'] = 1\n",
    "da0 = d.copy()\n",
    "da0['A'] = 0\n",
    "\n",
    "# NumPy arrays to simplify later data management\n",
    "y = np.asarray(d['Y'])\n",
    "a = np.asarray(d['A'])\n",
    "s = np.asarray(d['S'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c330611-9979-4bb6-87d0-56bd1bb8f16d",
   "metadata": {},
   "source": [
    "### Standard g-computation: X-only\n",
    "\n",
    "This first analysis only accounts for the variable related to selection bias. This is expected to be biased due to confounding bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f8fbd7-8dbb-4f18-85f1-a2530677b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(d[['I', 'A', 'X']])\n",
    "X1 = np.asarray(da1[['I', 'A', 'X']])\n",
    "X0 = np.asarray(da0[['I', 'A', 'X']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5ed680c-af96-4d43-9ad0-1ca3643ac71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the standard g-computation from above\n",
    "inits = [0., 0.5, 0.5, 0., 0., 0., ]\n",
    "estr = MEstimator(psi_sg, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39cf78d-7eea-4d74-a4be-a4cb56ae7fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard g-computation: X-only\n",
      "RD: -0.14571305869889267\n",
      "95% CI: [-0.22205721 -0.06936891]\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard g-computation: X-only\")\n",
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc975bb-0a88-452c-b3b6-1cba0f36956a",
   "metadata": {},
   "source": [
    "### Standard g-computation: Z-only\n",
    "\n",
    "This second analysis only accounts for the variable related to confounding bias. This is expected to be biased due to selection bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d757c6f-48fb-47ce-a663-59910573b229",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(d[['I', 'A', 'Z']])\n",
    "X1 = np.asarray(da1[['I', 'A', 'Z']])\n",
    "X0 = np.asarray(da0[['I', 'A', 'Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a04247c-37cd-406a-950d-374d2882a46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the standard g-computation from above\n",
    "inits = [0., 0.5, 0.5, 0., 0., 0., ]\n",
    "estr = MEstimator(psi_sg, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "671c3227-4ccd-4d54-8cab-53c32ba92061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD: -0.16551817082992823\n",
      "95% CI: [-0.22742265 -0.10361369]\n"
     ]
    }
   ],
   "source": [
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6883a56-7bf5-44f8-930d-69cfc496d7d2",
   "metadata": {},
   "source": [
    "### Standard g-computation: X & Z\n",
    "\n",
    "This third analysis only accounts for the variable related to selection and confounding bias. However, bias is still expected to occur due to the M-bias structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e354d76-7867-4c40-949e-e8dbe6ac18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(d[['I', 'A', 'X', 'Z']])\n",
    "X1 = np.asarray(da1[['I', 'A', 'X', 'Z']])\n",
    "X0 = np.asarray(da0[['I', 'A', 'X', 'Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd8db14-ae4a-4ba6-9989-8a8cf8a2188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the standard g-computation from above\n",
    "inits = [0., 0.5, 0.5, 0., 0., 0., 0., ]\n",
    "estr = MEstimator(psi_sg, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65e5d836-6297-44bc-a5d5-d691abb6e854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD: -0.1575507540776314\n",
      "95% CI: [-0.22976608 -0.08533542]\n"
     ]
    }
   ],
   "source": [
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcb5b4e-cd17-443c-a0f3-f0850bdd4e8c",
   "metadata": {},
   "source": [
    "### Nested g-computation\n",
    "\n",
    "This last analysis is using the proposed nested g-computation to account for both selection and confounding bias. This g-computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f11a0d-cad2-4c84-a7e1-01dbe93ce25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design matrix for inner expectation\n",
    "X = np.asarray(d[['I', 'A', 'X', 'Z']])\n",
    "X1 = np.asarray(da1[['I', 'A', 'X', 'Z']])\n",
    "X0 = np.asarray(da0[['I', 'A', 'X', 'Z']])\n",
    "\n",
    "# Design matrix for outer expectation\n",
    "W = np.asarray(d[['I', 'A', 'Z']])\n",
    "W1 = np.asarray(da1[['I', 'A', 'Z']])\n",
    "W0 = np.asarray(da0[['I', 'A', 'Z']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9295038-973f-4f80-9c7c-280997963ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_gcomp_nested(theta):\n",
    "    # Subset parameters for easier tracking in code later\n",
    "    idX = 3 + X.shape[1]\n",
    "    idW = idX + W.shape[1]\n",
    "    rd, r1, r0 = theta[0:3]\n",
    "    beta = theta[3:idX]\n",
    "    gamma_1 = theta[idX: idW]\n",
    "    gamma_0 = theta[idW:]\n",
    "\n",
    "    # Inner outcome nuisance model\n",
    "    ee_inner = ee_regression(beta, X=X, y=y, model='logistic')\n",
    "    ee_inner = ee_inner * s\n",
    "    y1hat = inverse_logit(np.dot(X1, beta))\n",
    "    y0hat = inverse_logit(np.dot(X0, beta))\n",
    "\n",
    "    # Outer outcome nuisance model\n",
    "    ee_outer1 = ee_regression(gamma_1, X=W, y=y1hat, model='logistic')\n",
    "    ee_outer0 = ee_regression(gamma_0, X=W, y=y0hat, model='logistic')\n",
    "\n",
    "    y1hat_outer = inverse_logit(np.dot(W1, gamma_1))\n",
    "    y0hat_outer = inverse_logit(np.dot(W0, gamma_0))\n",
    "\n",
    "    # Risk functions\n",
    "    ee_r1 = y1hat_outer - r1\n",
    "    ee_r0 = y0hat_outer - r0\n",
    "    ee_rd = np.ones(y.shape) * (r1 - r0 - rd)\n",
    "\n",
    "    return np.vstack([ee_rd, ee_r1, ee_r0, ee_inner, ee_outer1, ee_outer0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e215d1f-38f9-4839-bf94-57b6833d458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inits = [0., 0.5, 0.5, 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "estr = MEstimator(psi_gcomp_nested, init=inits)\n",
    "estr.estimate()\n",
    "ci = estr.confidence_intervals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d628fdca-4a34-4db7-8ec1-4e0f8ea679e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RD: -0.18917324702070035\n",
      "95% CI: [-0.25612398 -0.12222252]\n"
     ]
    }
   ],
   "source": [
    "print(\"RD:\", estr.theta[0])\n",
    "print(\"95% CI:\", ci[0, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6233f38d-b2ed-4ea9-be50-545e48e7d8d0",
   "metadata": {},
   "source": [
    "This concludes the second case study."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
